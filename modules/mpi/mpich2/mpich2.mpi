#!/bin/bash

#
# Copyright (c) 2006-2007 High Performance Computing Center Stuttgart,
#                         University of Stuttgart.  All rights reserved.
# Copyright (c) 2006-2007 Charles Loomis
#           (c) 2009-2010 Instituto de Fisica de Cantabria - CSIC. 
#

if test "x$MPI_START_MPI_PREFIX" = "x"  ; then    
    export MPI_START_MPI_PREFIX=/usr
    debug_msg "use default mpi path: $MPI_START_MPI_PREFIX"
fi

export HYDRA_MPIEXEC=0

# activate MPI
mpi_start_activate_mpi $MPI_START_MPI_PREFIX $MPI_START_MPI_MODULE
mpi_start_get_plugin "osc_mpiexec.sh" 1
. $MPI_START_PLUGIN_FILES

# further determine if the mpiexec is hydra 
if test $OSC_MPIEXEC -eq 0 ; then
    if test "x$MPI_MPIEXEC" != "x"; then
        # No mpiexec? try finding mpiexec.hydra
        MPIEXEC=`which mpiexec.hydra 2> /dev/null`
        if test $? -eq 0 -a "x$MPI_MPICH2_DISABLE_HYDRA" != "x1" ; then
            export HYDRA_MPIEXEC=1
            MPI_MPIEXEC=$MPIEXEC
        fi
    else
        # check if defined mpiexec is hydra
        $MPI_MPIEXEC -version 2>&1 | grep -i "hydra" > /dev/null 2>&1
        if test $? -eq 0 ; then
            export HYDRA_MPIEXEC=1
        fi
    fi
fi

# start an mpi job with mpd
mpich2_with_mpd () {
    debug_msg "assume it is safe to set the machinefile and number of processes"
    if test "x${MPI_START_NPHOST}" != "x" ; then
        debug_msg "Creating machine file for per node option"
        mpi_start_mktemp
        MACHINES=$MPI_START_TEMP_FILE
        for host in `cat "$MPI_START_HOSTFILE"` ; do 
            for ((i=0; i < MPI_START_NPHOST; i++)) ; do
                echo $host >> $MACHINES
            done
        done
    else
        if test $MPI_START_NP -gt $MPI_START_NSLOTS ; then
            debug_msg "Creating machine file for starting more processes than available slots"
            mpi_start_mktemp
            MACHINES=$MPI_START_TEMP_FILE
            while test `cat "$MACHINES" | wc -l` -lt $MPI_START_NP ; do
                cat "$MPI_START_MACHINEFILE" >> $MACHINES
            done
        else
            MACHINES=$MPI_START_MACHINEFILE
        fi
    fi
    local machines_params="-machinefile $MACHINES -np $MPI_START_NP"
    MPDBOOT_PARAMS="-n $MPI_START_NHOSTS -f $MPI_START_HOSTFILE"

    local SSH_AGENT=ssh
    if test "x$MPI_START_SSH_AGENT" != "x"; then
        # we are not using default start methods, setting specific ssh 
        debug_msg "setting specific ssh agent"
        MPDBOOT_PARAMS="$MPDBOOT_PARAMS --rsh=$MPI_START_SSH_AGENT"
        SSH_AGENT="$MPI_START_SSH_AGENT"
    fi

    # take care that the ".mpd.conf" file is available
    # make sure that we have a home, of not use pwd
    if test "x$HOME" == "x" ; then
        export HOME=$PWD
    fi
    echo "MPD_SECRETWORD=" > $HOME/.mpd.conf
    chmod 0600 $HOME/.mpd.conf

    # Assure that .mpd.conf is present at remote nodes
    # use provided ssh agent
    for MPI_START_REMOTE_NODE in `cat $MPI_START_HOSTFILE`; do
        if test $MPI_START_REMOTE_NODE = `hostname` -o $MPI_START_REMOTE_NODE = `hostname -f` -o $MPI_START_REMOTE_NODE = "localhost" ; then
            continue
        fi
        $SSH_AGENT $MPI_START_REMOTE_NODE "mkdir -p $HOME 2>&1 > /dev/null"
        if test $? -ne 0 ; then
            warn_msg "Unable to create $HOME at remote node, proably job will not start"
            continue
        fi
        cat $HOME/.mpd.conf | $SSH_AGENT $MPI_START_REMOTE_NODE cat ">" $HOME/.mpd.conf 
        # make sure correct permissions is set!
        $SSH_AGENT $MPI_START_REMOTE_NODE chmod 600 $HOME/.mpd.conf
        if test $? -ne 0 ; then
            warn_msg "Unable to copy .mpd.conf to remote node, proably job will not start"
        fi
    done

    # Start MPICH2 daemon.
    mpdboot $MPDBOOT_PARAMS 
    st=$?
    if test $st -ne 0 ; then
        error_msg "Unable to start MPD, aborting execution"
        dump_env
        exit 1
    fi

    MPI_GLOBAL_PARAMS="$MPI_GLOBAL_PARAMS $MPICH2_PARAMS $machines_params"

    # set the environment variables
    if test "x${MPI_START_ENV_VARIABLES}" != "x" ; then
        local envparam=""
        local first=1
        for var in ${MPI_START_ENV_VARIABLES}; do
            if test $first -eq 0 ; then
                envparam="${envparam},${var}"
            else
                envparam="-envlist $var"
                first=0
            fi
        done
        MPI_LOCAL_PARAMS="${MPI_LOCAL_PARAMS} ${envparam}"
    fi
    mpi_start_get_plugin "generic_mpiexec.sh" 1
    . $MPI_START_PLUGIN_FILES
    generic_mpiexec
    err=$?

    # Stop the daemon.
    mpdallexit
    return $err
}

#
# start an mpi job
#
mpi_exec () {
    if test "$MPI_START_SCHEDULER" = "slurm" ; then
        slurm_mpiexec
        return $?
    fi

    if test "x$MPI_MPIEXEC" != "x"; then
        MPIEXEC=$MPI_MPIEXEC
        MPI_GLOBAL_PARAMS=$MPI_SPECIFIC_MPIEXEC_PARAMS

        if test ${OSC_MPIEXEC} -eq  1 ; then
            I2G_MPIEXEC_COMM="pmi"
            osc_mpiexec 
            err=$?
        elif test ${HYDRA_MPIEXEC} -eq 1 ; then
            mpi_start_get_plugin "hydra.sh" 1
            . $MPI_START_PLUGIN_FILES
            HYDRA_EXTRA_PARAMS=$MPICH2_PARAMS
            mpiexec_with_hydra
            err=$?
        else
            mpich2_with_mpd
            err=$?
        fi
    elif test "x$MPI_MPIRUN" != "x"; then
        MPIEXEC=$MPI_MPIRUN
        MPI_GLOBAL_PARAMS=$MPI_SPECIFIC_MPIRUN_PARAMS
        mpich2_with_mpd
        err=$?
    else
        debug_msg "no mpiexec/mpirun found!"
        dump_env
        exit 1
    fi
    return $err
}


mpi_start () {
    mpi_start_get_plugin "generic_mpi_start.sh" 1
    . $MPI_START_PLUGIN_FILES
    generic_mpi_start
    return $?
}
